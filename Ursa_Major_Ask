#!/usr/bin/env python3
# The above shebang line ensures that the script runs with python3 interpreter

# Importing necessary libraries
# openai - an API to connect to OpenAI's language model
# config - a module containing configurations such as API keys
# subprocess - a module for running system commands
# argparse - a module for parsing command line arguments
import openai
import config
import subprocess
import argparse
import os
import gradio as gr

# Setting the API key for OpenAI's API
openai.api_key = config.OPENAI_API_KEY

def call_gpt(user_prompt, system_prompt):
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt}
    ]

    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=messages
    )
        # Extracting the system's message from the API response
    return response["choices"][0]["message"]["content"]

# Defining function to detect the script type. This function takes in a script text, sends it to OpenAI API, and returns the type of script.
def detect_script_type(script_text):
    # Initiating a conversation with GPT-3.5-turbo
    messages = [
            {"role": "system", "content": "You are a skilled AI capable of identifying the type of a given script. Your task is to determine the type of the script based on its content. Only return the two character name of the file extension based on the type script it is, do not include any extra text beside the two character file extension, do not include explanation or any examples whatsoever. just the two character file extension of the type of script it is. example: python scripts will return py and bash scripts will return sh and javascript files return js"},
        {"role": "user", "content": script_text}
    ]

    # Sending the conversation to the OpenAI API
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=messages
    )

    # Extracting the AI's message from the response
    ai_message = response["choices"][0]["message"]["content"]

    # Only returning the type of script
    # If the AI's message doesn't follow the expected format, return the whole message
    try:
        script_type = ai_message.split(':')[1].strip()
    except IndexError:
        script_type = ai_message

    return script_type

# Defining function to save a string (result1) to a file with a given file extension
def save_to_file(result1, file_extension):
    file_name = f"run.{file_extension}"
    with open(file_name, 'w') as f:
        f.write(result1)

# Defining function to strip triple backticks from a string (result1)
def strip_triple_backticks(result1):
    clean_result1 = result1.strip('```')
    return clean_result1

# Defining function to execute a script given a filename. It first makes the script executable then runs it.
def run_script(filename):
    try:
        # Change the file permissions to make it executable
        subprocess.run(['chmod', '+x', filename], check=True)

        # Run the script
        script_path = os.path.join('./', filename)
        result = subprocess.run(script_path, capture_output=True, text=True, check=True)

        print(result.stdout)
        return result.stdout

    except subprocess.CalledProcessError as e:
        print("Script execution failed with error: ", e.returncode)
        print("Error message: ", e.stderr)

# Defining function to strip leading dot from a string (file_extension)
def strip_dot(file_extension):
    return file_extension.lstrip('.')

# Defining function to remove blank first line from a string (result1)
def remove_blank_first_line(result1):
    # Split the text by lines
    lines = result1.split('\n')

    # Remove the first line if it's blank
    if lines[0].strip() == '':
        lines = lines[1:]

    # Join the lines back together and return the result
    return '\n'.join(lines)

# Running this via Gradio
def go_live_gradio(transcript, run_sscript, write_script):
    if run_sscript:
        # Append additional text
        transcript += " reply to this request with only the code, Dont explain anything but do use the shebang as the first line of the code. Don't wrap in a code block"

        # Getting the expert's response to the transcript
        result = call_gpt(transcript, "You are a Director of Research Computing at the University of California, Riverside. Ursa Major is a branded version of Google\'s GCP platform that uses the Google HPC Toolkit github site and google gcp researcher resources for help, information, and support. Slurm is the default cluster scheduler and it doesn\'t need walltime declarations and the default queue is named debug. Ursa Major uses Google Drive and GCS buckets for research storage and uses rclone to mount these to linux clusters. Respond to all input as an expert and give examples wherever possible.")

        clean_result = result_code_cleaning(result)

        # Detecting the script type
        file_extension = call_gpt(clean_result, "You are a skilled AI capable of identifying the progaramming language of a given script sample. Your task is to determine the programming language of the given script based on its content. Reply only with the two character name of the file extension, based on the type script it is, do not include any extra text beside the two character file extension, do not include explanation or any examples whatsoever. example: python scripts will return py, and bash scripts will return sh, and javascript files return js")

        # Removing leading dot from the file extension
        stripped_file_extension = strip_dot(file_extension)

        # Saving the script to a file
        save_to_file(clean_result, stripped_file_extension)

        # Constructing the filename
        file_name = f"run.{stripped_file_extension}"

        # Running the saved script
        outwindow = run_script(file_name)
        
        return outwindow
    elif write_script:
        # Append additional text
        transcript += "reply to script requests with only the code dont explain anything or y the code but do use the shebang as the first line."

        # Getting the Director's response to the transcript
        result = call_gpt(transcript, "You are a Director of Research Computing at the University of California, Riverside. Ursa Major is a branded version of Google\'s GCP platform that uses the Google HPC Toolkit github site and google gcp researcher resources for help, information, and support. Slurm is the default cluster scheduler and it doesn\'t need walltime declarations and the default queue is named debug. Ursa Major uses Google Drive and GCS buckets for research storage and uses rclone to mount these to linux clusters. Respond to all input as an expert and give examples wherever possible.")

        clean_result = result_code_cleaning(result)

        # Detecting the script type
        file_extension = call_gpt(clean_result, "You are a skilled AI capable of identifying the progaramming language of a given script sample. Your task is to determine the programming language of the given script based on its content. Reply only with the two character name of the file extension, based on the type script it is, do not include any extra text beside the two character file extension, do not include explanation or any examples whatsoever. example: python scripts will return py, and bash scripts will return sh, and javascript files return js")

        # Removing leading dot from the file extension
        stripped_file_extension = strip_dot(file_extension)

        # Saving the script to a file
        save_to_file(clean_result, stripped_file_extension)

        # Constructing the filename
        file_name = f"run.{stripped_file_extension}"

        return "File Written: " + file_name   
    else:
        return call_gpt(transcript, "You are a Director of Research Computing at the University of California, Riverside. Ursa Major is a branded version of Google\'s GCP platform that uses the Google HPC Toolkit github site and google gcp researcher resources for help, information, and support. Slurm is the default cluster scheduler and it doesn\'t need walltime declarations and the default queue is named debug. Ursa Major uses Google Drive and GCS buckets for research storage and uses rclone to mount these to linux clusters. Respond to all input as an expert and give examples wherever possible.")

# 
def result_code_cleaning(result):
    return remove_blank_first_line(remove_first_line_if_not_shebang(strip_triple_backticks(result)))

def remove_first_line_if_not_shebang(text):
    lines = text.split('\n')
    if not lines[0].startswith("#!/"):
        return '\n'.join(lines[1:])
    return text

import subprocess

def run_ls_latr():
    """Runs ls -latr on the current directory and returns the contents as a string."""
    ls_latr_command = ["ls", "-latr"]
    ls_latr_output = subprocess.check_output(ls_latr_command, text=True)
    #ls_latr_contents = ls_latr_output.decode("utf-8")
    return ls_latr_output

def main(args):
    # Joining the transcript arguments with newline characters in between
    transcript = '\n'.join(args.transcript)
    if args.run:
        # Append additional text
        transcript += " reply to this request with only the code dont explain anything or but do use the shebang as the first line."
        result = call_gpt(transcript, "You are a Director of Research Computing at the University of California, Riverside. Ursa Major is a branded version of Google\'s GCP platform that uses the Google HPC Toolkit github site and google gcp researcher resources for help, information, and support. Slurm is the default cluster scheduler and it doesn\'t need walltime declarations and the default queue is named debug. Ursa Major uses Google Drive and GCS buckets for research storage and uses rclone to mount these to linux clusters. Respond to all input as an expert and give examples wherever possible.")
        clean_result = result_code_cleaning(result)
        file_extension = call_gpt(clean_result, "You are a skilled AI capable of identifying the progaramming language of a given script sample. Your task is to determine the programming language of the given script based on its content. Reply only with the two character name of the file extension, based on the type script it is, do not include any extra text beside the two character file extension, do not include explanation or any examples whatsoever. example: python scripts will return py, and bash scripts will return sh, and javascript files return js")
        stripped_file_extension = strip_dot(file_extension)

        # Saving the script to a file
        save_to_file(clean_result, stripped_file_extension)

        # Constructing the filename
        file_name = f"run.{stripped_file_extension}"

        # Running the saved script
        run_script(file_name)

        print("completed running: " + file_name)

        exit()
    elif args.write:
        # Append additional text
        transcript += "reply to script requests with only the code dont explain anything or y the code but do use the shebang as the first line."

        # Getting the Director's response to the transcript
        result = call_gpt(transcript, "You are a Director of Research Computing at the University of California, Riverside. Ursa Major is a branded version of Google\'s GCP platform that uses the Google HPC Toolkit github site and google gcp researcher resources for help, information, and support. Slurm is the default cluster scheduler and it doesn\'t need walltime declarations and the default queue is named debug. Ursa Major uses Google Drive and GCS buckets for research storage and uses rclone to mount these to linux clusters. Respond to all input as an expert and give examples wherever possible.")

        clean_result = result_code_cleaning(result)

        # Detecting the script type
        file_extension = call_gpt(clean_result, "You are a skilled AI capable of identifying the progaramming language of a given script sample. Your task is to determine the programming language of the given script based on its content. Reply only with the two character name of the file extension, based on the type script it is, do not include any extra text beside the two character file extension, do not include explanation or any examples whatsoever. example: python scripts will return py, and bash scripts will return sh, and javascript files return js")

        # Removing leading dot from the file extension
        stripped_file_extension = strip_dot(file_extension)

        # Saving the script to a file
        save_to_file(clean_result, stripped_file_extension)

        # Constructing the filename
        file_name = f"run.{stripped_file_extension}"

        print("File Written: " + file_name)
        exit()
    elif args.live:
        #ls_latr_contents = run_ls_latr()
        #ls_latr_contents = run_ls_latr().replace('\n', '<br>')
        ls_latr_contents = run_ls_latr().replace('\n', '  \n')
        from gradio.components import Textbox, Checkbox
        iface = gr.Interface(fn=go_live_gradio,
                    inputs=[Textbox(lines=1, label="Question"),
                        Checkbox(label="Run Script"),
                        Checkbox(label="Write File")],
                    outputs="text",
                    title="Ursa Major Ask",
                    description="""Ursa Major Ask is a command-line tool that uses OpenAI's GPT-3.5-turbo to simulate a conversation with an expert in the Google Ursa Major platform. The script accepts a transcript as a command-line argument, and the generated response is treated as a script that can be written to file, run, or even displayed on a gradio interface. The script has many capabilities, including generating and running Python, bash, or Slurm scripts, automating genomics pipelines, analyzing data files, and interpreting JSON or XML files.""",
                    examples=[
                            ["What storage is avaiable to me?"],
                            ["How do I move files to a Ursa Major Cluster?"],
                            ["What is Ursa Major?"],
                            ["How do I share the results of my Ursa Major research?"],
                            ["Generate a script that runs a Slurm submission script that load the module openai and runs a Python script called my_analysis.py on the partition named research and lets run on 1 node and 12 cores"],
                            ["Generate a script that will print the status of my slurm jobs"],
                            ["Generate a matlab input file that shows an example of how to run matlab code on a gpu"],
                            ["write a script to generate a file called data.csv with 100 rows and 10 columns of example data with a hidden trend"],
                            ["Analyze the following $(cat data.csv) and return a script to use matplotlib to further analyze the data and write to a file"],
                            ["write a Nextflow script that takes as input 'reads.fastq', runs FastQC for quality control, uses Trimmomatic for trimming, aligns with BWA, and finally calls variants with FreeBayes."],
                            ["write a Bash script that runs FastQC on 'sample.fastq', trims the adapters using Trimmomatic, and then aligns the reads to the 'reference.fa' genome using HISAT2."],                             
                            ["write a Bash script that installs nvidia drivers and cuda and suite of the most command data science and ml tools"]
                            ],
                    article=f'''
                    Contents of Current Dir.
                    {ls_latr_contents}
                            '''
                            )
        # Launch the interface
        iface.launch(share = True)
    else:
        # Getting the Director's response to the transcript
        print(call_gpt(transcript, "You are a Director of Research Computing at the University of California, Riverside. Ursa Major is a branded version of Google\'s GCP platform that uses the Google HPC Toolkit github site and google gcp researcher resources for help, information, and support. Slurm is the default cluster scheduler and it doesn\'t need walltime declarations and the default queue is named debug. Ursa Major uses Google Drive and GCS buckets for research storage and uses rclone to mount these to linux clusters. Respond to all input as an expert and give examples wherever possible."))

# Ensuring that the following code only runs when this script is run directly (and not when it is imported as a module)
if __name__ == "__main__":

    # Creating an ArgumentParser object
    parser = argparse.ArgumentParser()
    
    # Adding an argument for the transcript
    parser.add_argument("transcript", nargs='*', type=str, help="Transcript of the conversation")

    # Adding an optional argument to indicate whether to run the generated script
    parser.add_argument("-r", "--run", action='store_true', help="Run the generated script")
    parser.add_argument("-l", "--live", action='store_true', help="Run using a gradio interface")
    parser.add_argument("-w", "--write", action='store_true', help="Write the generated script")
  
    # Parsing the command line arguments
    args = parser.parse_args()

    main(args)
